# Home_Sales-Module 22 

# Introduction 
This Module looks at Home Sales, using the Pyspark and SparkSQL 

# Table of Contents
INTRODUCTION
DESCRIPTION
INSTALLATION
CREDITS


# Description

By using the Pyspark, and SparkSQL functions, we can run large amounts of data and store it without using much memory on our systems. This is a easy and very 
cost saving approach for companies. By using the Home Sales dataset, we were able to run dataset through the URL using PySpark, and analyzing the data 
using SparkSQL. By using the parquet and caching techniques, this allows us to store the data efficiently on our systems.

# Installation

Jupyter Notebook
PySpark and SparkSQL 
Parquet, Caching 

# Credits

Arun Balaram
ASK BCS
